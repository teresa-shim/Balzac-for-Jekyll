---
layout: post
title: "하둡 프로그래밍 1"
date: 2016-09-27 14:51:30 +0900
---

# Chapter 1. 하둡 살펴보기

## 1.1 빅데이터의 시대
 
### 빅데이터의 개념

- 데이터 규모에 초점: 기존 데이터베이스 관리도구의 데이터 수집, 저장, 관리, 분석하는 역량을 넘어서는 데이터
- 업무 수행 방식에 초점: 다양한 종류의 대규모 데이터로부터 저렴한 비용으로 가치를 추출하고, 데이터의 빠른 수집, 발굴, 분석을 지원하도록 고안된 차세대 기술 및 아키텍처

### BI/DW 리서치 기관 TDWI에서 정의한 빅데이터 3대 요소(3V)
- 크기(Volume): 비즈니스 특성에 따라 다를 수 있지만 일반적으로 TB~PB이상. 이런 빅데이터는 기존 파일 시스템에 저장하기도 어렵고, 기존 데이터웨어하우스 같은 솔루션에서 소화하기도 어렵기 때문에 분산 컴퓨팅 기법으로 접근해야 한다. 분산 컴퓨팅 솔루션으로는 구글의 GFS와 아파티의 하둡이 있고, 대용량 병렬 처리 데이터베이스로는 EMC의 GreenPlum, HP의 Vertica, IBM의 Netezza, 테라데이터의 Kickfire 등이 있다.
- 속도(Velocity): 빅데이터의 속도적인 특징은 크게 실시간 처리와 장기적인 접근으로 나눌 수 있다. 오늘날 디지털 데이터는 매우 빠른 속도로 생성되기 때문에 데이터의 생산, 저장, 유통, 수집, 분석이 실시간으로 처리되어야 한다는 것. 뿐만 아니라 수집된 데이터를 다양한 분석 기법과 표현 기술로 분석해야 하고, 장기적이고 전략적인 차원에서 접근해야 한다.
- 다양성(variety): 다양한 종류의 데이터들이 빅데이터를 구성하고 있다. 정형화 종류에 따라 정형, 반정형, 비정형으로 나뉘어진다.
	- 정형: 정형화된 데이터로, 고정된 필드에 저장되는 데이터. 기존 솔루션을 이용해 비교적 쉽게 보관, 분석, 처리 작업을 진행할 수 있다.
	- 반정형: 고정된 필드로 저장되지는 않지만 XML이나 HTML같이 메타데이터나 스키마를 포함하는 데이터.
	- 비정형: 고정된 필드에 저장되지 않는 데이터. 동영상, 사진, 오디오, 메신저 대화 내용, 위치 정보, 통화 내용 등 다양한 비정형 데이터가 존재한다.

	이러한 빅데이터의 3대 요소 중 2가지 이상 충족한다면 빅데이터라고 볼 수 있다.

###빅데이터의 출현 배경

 데이터 폭증의 시대: 최근 2년간 생산된 데이터가 인류가 그 전까지 생산한 데이터보다 많음, 전 세계에서 만들어지는 데이터의 양은 매년 40%씩 증가하고 있음. 데이터는 앞으로도 매년 2배 이상씩 증가할 것으로 예상. 
 빅데이터가 여러 분야에서 활용되고, 성공하는 예시가 많아짐.
 
 ->빅데이터의 중요성 증가.

## 1.2 하둡이란?

 하둡(HADOOP): 대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈소스 프레임워크. 구글이 논문으로 발표한 GFS(Google File System)와 MapReduce를 더그 커팅(Doug Cutting)이 구현한 결과물. 분산 파일 시스템인 HDFS(Hadoop Distributed File System)에 데이터를 저장하고, 분산처리 시스템인 MapReduce를 이용해 데이터를 처리한다.

 하둡의 장점: 오픈소스 프로젝트이기 때문에 라이선스 비용 부담이 없다. 또한, x86 CPU에 리눅스 서버면 설치해 운영할 수 있다. 용량이 부족하면 필요한 만큼 리눅스 서버만 추가하면 되고, 데이터의 복제본을 저장하기 때문에 데이터의 유시이나 장애 발생 시에도 복구가 가능하다. 또한, 여러 대의 서버에 데이터를 저장하고, 데이터가 저장된 각 서버에서 동시에 데이터를 처리하는 분산 컴퓨팅을 이용하기 때문에 데이터 처리 속도가 매우 빠르다. 

##1.3 하둡 에코시스템
 
 하둡 에코시스템은 하둡 생태계라고 표현하기도 한다. 분산 데이터를 저장하는 HDFS와 분석 데이터를 처리하는 MapReduce가 하둡 코어 프로젝트이고 나머지는 모두 하둡의 서브 프로젝트이다.

### 코디네이터

- Zookeeper (http://zookeeper.apache.org)
	분산 환경에서 서버 간의 상호 조정이 필요한 서비스를 제공하는 시스템.
	1. 하나의 서버에만 서비스가 집중되지 않게 서비스를 알맞게 분산한다.
	2. 하나의 서버에서 처리한 결과를 다른 서버와도 동기화해서 데이터의 안정성을 보장한다.
	3. active 서버에 문제가 발생해 서비스를 제공할 수 없을 경우 대기중인 다른 서버를 active 서버로 바꾸어 서비스가 중지 없이 제공되게 합니다.
	4. 분산 환경을 구성하는 서버의 환경설정을 통합적으로 관리합니다. 

### 리소스 관리

- YARN (http://hadoop.apache.org)
	데이터 처리 작업을 실행하기 위한 클러스터 지원(CPU, 메모리, 디스크 등)과 스케쥴링을 위한 프레임워크. 기존 데이터 처리 프레임워크인 MapReduce의 단점을 극복하기 위해 시작된 프로젝트이며, 하둡 2.0부터 이용할 수 있다. MapReduce, 하이브, 임팔라, 타조, 스파크 등 다양한 애플리케이션들이 YARN에서 리소스를 할당 받아 작업을 실행한다.
- Mesos (http://mesos.apache.org)
	클라우드 인프라스트럭쳐 및 컴퓨팅 엔진의 다양한 자원(CPU, 메모리, 디스크)을 통합적으로 관리할 수 있도록 만든 자원관리 프로젝트. 클러스터링 환경에서 동적으로 자원을 할당하고 격리하는 메커니즘을 제공하며 웹 기반의 UI, 자바, C++, 파이썬 API를 제공한다. 하둡, 스파크, 스톰, 엘라스틱 서치, 카산드라, 젠킨스 등 다양한 애플리케이션을 Mesos에서 실행할 수 있다.

### 데이터 저장

- HBase (http://hbase.apache.org)
	HDFS 기반의 칼럼 기반 데이터베이스. 실시간 랜덤 조회 및 업데이트가 가능하며, 각 프로세스는 개인의 데이터를 비동기적으로 업데이트할 수 있다. 단, MapReduce는 일괄 처리 방식으로 수행된다.
- Kudu (http://getkudu.io)
	컬럼 기반의 스토리지로서, 특정 컬럼에 대한 데이터 읽기를 고속화할 수 있다. 물론 기존 HDFS에서 파케이(Parquet), RC, ORC와 같은 파일 포맷을 사용하면 칼럼 기반으로 데이터를 저장할 수 있지만, HDFS 자체가 온라인 데이터 처리에 적합하지 않다는 약점이 있다. 또한 HBase의 경우 데이터 분석 처리가 느리다는 단점이 있다. Kudu는 이러한 문제점을 보완해서 개발한 컬럼 기반 스토리지이며, 데이터의 발생부터 분석까지 시간을 단축할 구 있다.

### 데이터 수집

- Chukwa (http://chukwa.apache.org)
	분산 환경에서 생성되는 데이터를 HDFS에 안정적으로 저장하는 플랫폼. 분산된 각 서버에서 agent를 실행하고, collector가 agent로부터 데이터를 받아 HDFS에 저장한다. collector는 100개의 agent당 하나씩 구동되며, 데이터 중복 제거 등의 작업은 MapReduce로 처리한다.
- Flume (http://flume.apache.org)
	Chukwa처럼 분산된 서버에 에이전트가 설치되고, 에이전트로부터 데이터를 전달받는 콜랙터로 구성된다. 차이점은 전체 데이터 흐름을 관리하는 마스터 서버가 있어서 데이터를 어디서 수집하고, 어떤 방식으로 전송하고, 어디에 저장할지를 동적으로 변경할 수 있다.
- Scribe (https://github.com/facebook/scribe)
	페이스북에서 개발한 데이터 수집 플랫폼이며, Chukwa와는 다르게 데이터를 중앙 집중 서버로 전송하는 방식이다. 최종 데이터는 HDFS 외에 다양한 저장소를 활용할 수 있으며, 설치와 구성이 쉽게 다양한 프로그램 언어를 지원한다. HDFS에 저장하려면 JNI(Java Native Interface)를 이용해야 한다.
- Sqoop (http://sqoop.apache.org)
	대용량 데이터 전송 솔루션. Sqoop은 HDFS, RDBMS, DW, NoSQL 등 다양한 저장소에 대용량 데이터를 신속하게 전송하는 방법을 제공한다. 오라클, MS-SQL, DB2 등과 같은 상용 RDBMS와 MySQL, PostgreSQL과 같은 오픈소스 RDBMS 등을 지원한다.
- Hiho (https://github.com/sonalgoyal/hiho)
	Sqoop과 같은 대용량 데이터 전송 솔루션이며 현재 GitHub에 공개되어 있다. 하둡에서 데이터를 가져오기 위한 SQL을 지정할 수 있으며, JDBC 인터페이스를 지원한다. 현재는 오라클과 MySQL의 데이터 전송만 지원한다.
- Kafka (http://kafka.apache.org)
	데이터 스트림을 실시간으로 관리하기 위한 분산 메시징 시스템. publish-subscribe 모델로 구성되어 있으며, 데이터 손실을 막기 위해 디스크에 데이터를 저장한다. 파티셔닝을 지원하기 때문에 다수의 카프카 서버에서 메시지를 분산 처리할 수 있으며, 시스템 안정성을 위하여 로드밸런싱과 내고장성(Fault Tolerant)을 보장한다.

### 데이터 처리

- Pig (http://pig.apache.org)
	복잡한 MapReduce 프로그래밍을 대체할 피그 라틴(Pig Latin)이라는 자체 언어를 제공한다. MapReduce API를 매우 단순화한 형태이고 SQL과 유사한 형태로 설계되었다. 하지만 SQL과 유사하기만 할 뿐, 기존 SQL 지식을 활용하기가 어려운 편이다.
- Mahout (http://mahout.apache.org)
	하둡 기반으로 데이터 마이닝 알고리즘을 구현한 오픈소스 프로젝트. 현재 Classification, Clustering, Recommenders/collaborative filtering, Pattern Mining, Regression, Dimension reduction, Evolutionary Algorithm 등 주요 알고리즘을 지원한다.
- Spark (http://spark.apache.org)
	인메모리 기반의 범용 데이터 처리 플랫폼. 배치 처리, 머신러닝, SQL 질의 처리, 스트리밍 데이터 처리, 그래프 라이브러리 처리와 같은 다양한 작업을 수용할 수 있도록 설계되어 있다.
- Impala (http://impala.io)
	클라우데라에서 개발한 하둡 기반의 분산 쿼리 엔진. MapReduce를 사용하지 않고, C++로 개발한 인메모리 엔진을 사용해 빠른 성능을 보여준다. 데이터 조회를 위한 인터페이스로 HiveQL을 사용하며, 수초 내에 SQL 질의 결과를 확인ㄴ할 수 있다.
- Presto (https://prestodb.io)
	페이스북이 개발한 대화형 질의를 처리하기 위한 분산 쿼리 엔진. 메모리 기반으로 데이터를 처리하며, 다양한 데이터 저장소에 저장된 데이터를 SQL로 처리할 수 있다. 특정 질의의 경우 하이브 대비 10배정도 빠른 성능을 보여준다. 
- Hive (http://hive.apache.org)
	하둡 기반의 데이터웨어하우징용 솔루션. 페이스북에서 개발해 오픈소스로 공개되며 주목 받은 기술. SQL과 매우 유사한 HiveQL이라는 쿼리 언어를 제공한다. 따라서 자바를 모르는 데이터 분석가들도 쉽게 하둡 데이터를 분석할 수 있게 도와준다. HiveQL은 내부적으로 MapReduce 잡으로 변환되어 실행된다. 
- Tajo (http://tajo.apache.org)
	고려대학교 박사 과정 학생들이 주도해서 개바한 하둡 기반의 데이터 웨어하우스 시스템. MapReduce 엔진이 아닌 자체 분산 처리 엔진을 사용하며, HiveQL을 사용하는 사용하는 가른 시스템과는 다르게 표준 SQL을 지원하는 것이 특징. HDFS, AWS S3, HBase, DBMS 등에 저장된 데이터 표준 SQL로 조회할 수 있고, 이기종 저장소 간의 데이터 조인 처리도 가능하다. 질의 유형에 따라 Hive나 Spark보다 1.5~10배 빠른 성능을 보여준다.

### 워크플로우 관리

- Oozie (http://oozie.apache.org)
	하둡을 관리하는 워크플로우 및 코디네이터 시스템. 자바 서블릿 컨테이너에서 실행되는 자바 웹 애플리케이션 서버이며, MapReduce 작업이나 Pig 작업 같은 특화된 액션으로 구성된 워크플로우를 제어한다.
- Airflow (http://nerds.airbnb.com/airflow)
	에어비앤비에서 개발한 워크플로우 플랫폼이다. 데이터 흐름의 시각화, 스케줄링, 모니터링이 가능하며, Hive, Presto, DBMS 엔진과 결합해서 사용할 수 있다.
- Azkaban (https://azkaban.github.io)
	Linked In에서 개발한 워크플로우 플랫폼. Azkaban은 워크플로우 스케쥴러, 시각화된 절차, 인증 및 권한 관리, 작업 모니터링 및 알람 등 다양한 기능을 웹UI로 제공한다.
- Nifi (https://nifi.apache.org)
	데이터 흐름을 모니터링 하기 위한 프레임워크. 여러 네트워크를 통과하는 데이터 흐름을 웹UI에서 그래프로 표현하며, 프로토콜과 데이터 형식이 다르더라도 분석이 가능하다. 또한 데이터를 흘려 보낼 때 우선순위를 제어할 수 있다.

### 데이터 시각화

- Zeppelin (https://zeppelin.incubator.apache.org)
	빅데이터 분석가를 위한 웹 기반의 분석도구. 분석결과를 즉시 표, 그래프로 표현하는 시각화까지 지원한다. iPython의 Notebook과 유사한 노트북 기능을 제고하며, 분석가는 이를 통해 손쉽게 데이터를 추출, 정제, 분석, 공유할 수 있다. 또한 Spark, Hive, Tajo, Flink, 엘라스틱 서치, 카산드라, DBMS 등 다양한 분석 플랫폼과 연동할 수 있다.

### 데이터 직렬화

- Avro (http://avro.apache.org)
	RPC(Remote Procedure Call)와 데이터 직렬화를 지원하는 프레임워크. JSON을 이용해 데이터 형식과 프로토콜을 정의하며, 작고 빠른 바이너리 포맷으로 데이터를 직렬화한다. 경쟁 솔루션으로는 아파치 Thrift, 구글 Protocol Buffer 등이 있다.
- Thrift (http://thrift.apache.org)
	서로 다른 언어로 개발된 모듈들의 통합을 지원하는 RPC 프레임워크. 개발자가 데이터 타입과 서비스 인터페이스를 선언하면 RPC 형태의 클라이언트와 서버 코드를 자동으로 생성합니다. 자바, C++, C#, 펄, PHP, 파이썬, 델파이, 얼랭, Go, Node.js 등과 같은 다양한 언어를 지원한다.

## 1.4 하둡에 대한 오해

- RDBMS를 대체한다.
	기존 RDBMS를 대체하지 않고, 오히려 상호보완적인 특성을 띠고 있다. BI(Business Intelligence)나 OLAP(On-line Analytical Processing) 시스템을 이용하는 기업은 데이터를 처리하기 위해 ETL(Extraction, Transform, Loading: RDBMS나 로그 파일 등 다양한 데이터 소스로부터 필요한 데이터를 추출, 변환해 DW(Data Warehouse) 혹은 DM(Data Mart)에 전송, 적재하는 과정)과정을 거친다. 하둡은 ETL 과정에 도움을 줄 수 있다. 또한, 하둡은 배치성으로 데이터를 저장하거나 처리하는데 적합한 시스템으로 구성되어 있기 때문에 무결성을 반드시 보장되어야 하는 데이터를 처리하는 데에는 부적합하다. 따라서 데이터 무결성이 중요한 데이터는 RDBMS에서 처리하고, 하둡은 배치성으로 데이터를 저장하고 처리하는데 쓰는 것이 좋다.
- 하둡은 NoSQL이다.
	하둡이 RDBMS에 속하는 것은 아니지만, 그렇다고 NoSQL의 핵심 기능인 데이터베이스 시스템의 역할을 수행하는 것도 아니다.

## 1.5 하둡의 과제

- 고가용성 지원
	가용성이란 시스템 장애 발생 후 정상으로 되돌아오는 상태를 분석하는 척도를 말한다. 고가용성은 99.999% 상태의 가용을 의미하는데 이는 1년 중 30분 정도를 제외하고 서비스가 가능한 수치이다. 하둡은 HDFS에 데이터를 저장하고 HDFS는 네임노드와 데이터노드로 구성되는데, 네임노드가 HDFS에 저장하는 모든 데이터의 메타 정보를 관리한다. 네임노드에 장애가 발생하게 되면 데이터를 더는 HDFS에 저장할 수 없고, 네임노드의 데이터가 유실되면 기존에 저장된 파일도 조회할 수 없게 된다. 책이 쓰여질 당시 하둡은 네임노드에 대한 고가용성이 지원되지 않았지만, 2013년 2.0 정식 버전부터는 지원하기 시작했다.
- 파일 네임스페이스 제한
	네임노드가 관리하는 메타 정보는 메모리로 관리되기 때문에 메모리의 용량에 따라 HDFS에 저장하는 파일과 디렉토리 개수가 제한을 받는다.
- 데이터 수정 불가
	파일의 이동이나 이름 변경과 같은 작업은 가능하지만 저장된 파일의 내용을 수정할 수는 없다. 하지만 하둡 0.21버전에서는 기존에 저장된 파일에 내용을 붙일 수 있는 덧붙임(append) 기능이 제공된다.
- POSIX 명령어 미지원
	기존 파일 시스템에서 사용하던 POSIX 형식의 파일 명령어를 사용할 수 없고 하둡에서 제공하는 별도의 셀 명령어와 API를 이용해 파일을 제어해야 한다.
- 전문 업체 부족
	상용 DBMS는 벤더나 다양한 유지보수 업체가 있지만, 아직 국내에는 하둡과 관련된 다양한 업체가 부족하다. 또한, 다양한 외상 벤더들이 하둡 솔루션을 선보이고 있지만, 오랫동안 이 분야에 기술과 노하우를 쌓아온 인터넷 업체에 비해 내공이 떨어질 수 밖에 없다. 



